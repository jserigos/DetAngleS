{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the Gold Stanard NACC file to find how labeled anglicisms are POS & NE tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish: 37940 English 57852\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter\n",
    "nlp_sp = spacy.load('es', parse=True, tag=True, entity=True)\n",
    "nlp_en = spacy.load('en', parse=True, tag=True, entity=True)\n",
    "print(\"Spanish:\", len(nlp_sp.vocab), \"English\", len(nlp_en.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lexeme.Lexeme at 0x122714948>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_en.vocab[\"d3fasd\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to combine punctuation with the preceding word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_punctuation(seq, characters='.,:;?!'):\n",
    "    characters = set(characters)\n",
    "    seq = iter(seq)\n",
    "    current = next(seq)\n",
    "\n",
    "    for nxt in seq:\n",
    "        if nxt in characters:\n",
    "            current += nxt\n",
    "        else:\n",
    "            yield current\n",
    "            current = nxt\n",
    "\n",
    "    yield current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NACC_df = pd.read_csv('Data/NACC-GoldStandard.tsv',delimiter='\\t',encoding='utf-8', header=0)\n",
    "NACC_tokens = NACC_df[\"Token\"].tolist()\n",
    "NACC_punct_joined = join_punctuation(NACC_tokens)\n",
    "NACC_text = \" \".join(NACC_punct_joined)\n",
    "NACC_spacy = nlp_sp(NACC_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add new columns to the pandas dataframe for POS, NE, and Lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NACC_df[\"POS\"] = [token.pos_ for token in NACC_spacy]\n",
    "NACC_df[\"NE\"] = [token.ent_iob_ for token in NACC_spacy]\n",
    "NACC_df[\"Lemma\"] = [token.lemma_ for token in NACC_spacy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the dataset to only analysis those tokens labeled as anglicisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_anglicism =  NACC_df['Anglicism']==\"yes\"\n",
    "for value, count in Counter(NACC_df[is_anglicism][\"POS\"]).most_common():\n",
    "    print(value, count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_openclass =  NACC_df['POS'].isin([\"NOUN\", \"VERB\", \"PROPN\", \"ADJ\"])\n",
    "print(round(100*len(NACC_df[is_openclass]) / len(NACC_df), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All anglicisms in the Goldstandard are labeled as {'NOUN': 62, 'VERB': 8, 'PROPN': 7, 'ADJ': 4}, which are the open class pos tags. This is in keeping with the borrowablity scale so filtering out all other POS tags appears to be both theortically and practically sound. \n",
    "The majority of anglicisms are labeled as not named entities but a few are unexpected one (i.e. not capitalized) so a simple capitalization test maybe better. I think anglicisms that are towards the beginning of the sentence get confused for NE because they are OOV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value, count in Counter(NACC_df[is_anglicism][\"NE\"]).most_common():\n",
    "    print(value, count)\n",
    "a = NACC_df[is_anglicism]\n",
    "is_NE =  a['NE'].isin([\"I\", \"B\"])\n",
    "print(a[is_NE])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around 40% of the data is in open class POS tag (\"NOUN\", \"VERB\", \"PROPN\", \"ADJ\") so by filtering out all other data (closed class), we will eliminate the need to test 60% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = NACC_df.to_csv (r'Data/NACC-Spacy-annotated.csv', index = None, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nlp_sp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
